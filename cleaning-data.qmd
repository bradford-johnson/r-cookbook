# **Cleaning Data**

Cleaning data is one of the most important steps to any data analytics project. Cleaning data can involve anything from changing the case of characters from uppercase to lowercase to removing outliers from a data set, or even figuring out what to do with missing values. Having clean data is essential for making recommendations to stakeholders, as your analysis can only be as strong as your data is clean.

There are countless ways to clean your data in R, and I will show you different ways I have cleaned up data sets.

## **Column Names (Headers)**

Dealing with dirty data is part of being a data analyst, and the `janitor` package is great because it can help clean up the headers (or column names) so they are easier to work with. I will load in the `readr` package to import a hand crafted `.csv` that I made as an example. I will also load in the `dplyr` package so I can pipe the data into functions.

Here is how you install and load the packages.

```{r eval=FALSE}
install.packages("janitor")
install.packages("readr")
install.packages("dplyr")
```

```{r warning=FALSE,message=FALSE}
library(janitor)
library(readr)
library(dplyr)
```

Now I will load in the data frame with dirty column names / headers.

```{r warning=FALSE,message=FALSE}
# read in csv with no changes
dirty_df <- read_csv('janitor-example.csv')
```

Here is what the dirty data frame looks like.

```{r}
dirty_df %>% 
  head()
```

Now using the `clean_names()` function from the `janitor` package along with some `mutate()` functions I will load in the same data frame.

```{r warning=FALSE,message=FALSE}
# read in csv but with janitor and dplyr functions
clean_df <- read_csv('janitor-example.csv') %>%
  clean_names() %>%
  mutate(weather_condition = w_ea_th_er_conditions) %>%
  mutate(avg_temp_f = temp_f) %>%
  mutate(weekday = day_of_the_week) %>%
  select(weekday, avg_temp_f, weather_condition)
```

Here is how the cleaned data frame looks. The column names are now easier to work with, and much better understood.

```{r}
clean_df %>%
  head()
```

## **Filter and Mutate Data**

Many times you may need to filter data, for example if you only want to see observations on a specific weekday, or with certain values. That is easy to do and with the `dplyr` package you will be able to really be creative with filtering, creating additional columns, and much more.

For some of these examples I will use some data sets that come with R, the first data set we will look at is `chickwts` which looks at baby chick weights and feed types. I am going to summarize the counts for the feeds to quickly see all the options. Then I will filter some of the feeds as they are no longer available for my stakeholder in this scenario.

```{r}
# load packages and data 
library(dplyr)

chick_df <- chickwts

# counts for each feed type
chick_df %>%
  group_by(feed) %>%
  summarise(n = n())
```

```{r}
# keep feeds: sunflower, soybean, linseed
chick_feeds <- chick_df %>%
  filter(feed == 'sunflower' | feed == 'soybean' | feed == 'linseed')

# counts for each type of feed
chick_feeds %>%
  group_by(feed) %>%
  summarise(n = n())
```

How about a different filter that returns all rows that have weights below 200 units, and are linseed or horsebean feeds.

```{r}
chick_df %>%
  filter(weight < 200 & feed == 'linseed' | weight < 200 & feed == 'horsebean')
```

Now I am going to use the `mutate()` function to create a new column, and this column will be used to classify a chicks weight category based on some predetermined values.

> For this example lets say these are the weight classes:
>
> > weight \< 200 - **underweight**
> >
> > weight \>= 200 & weight \<= 300 - **normal**
> >
> > weight \> 300 - **overweight**

```{r}
# mutate() and casewhen()
chick_classes <- chick_df %>%
  mutate(weight_class = case_when(
    weight < 200 ~ 'underweight',
    weight >= 200 & weight <= 300 ~ 'normal',
    weight > 300 ~ 'overweight'
    ))

# weight class count table 
chick_classes %>% 
  group_by(weight_class) %>%
  summarise(n = n())
```

## **Removing Outliers**

This image is from [DataCamp's](https://campus.datacamp.com/courses/introduction-to-statistics-in-r/summary-statistics?ex=10) learning platform, and it shows a visual of a boxplot, and the outliers on either side of the distribution. To find the outliers on the lower range you do the following equation `Q1 - 1.5 x IQR`. To find outliers on the upper range you use this equation `Q3 + 1.5 * IQR`.

![](data-camp-outliers.png)

You can use those equations to then filter out the outliers and then continue with your analysis. I have created some data with outliers to show how you would do this in R.

```{r include = FALSE}
# load in tidyverse package and patchwork for multiple plots
library(tidyverse)
library(patchwork)

# read in data from .csv
outlier_df <- read_csv("outlier-data.csv")

# boxplot visual of data
outlier_p <- outlier_df %>%
  ggplot(aes(x = var1)) +
  geom_boxplot() + 
  theme_classic() +
  labs(title = "With Outliers") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

```{r warning=FALSE,message=FALSE}
# remove outliers steps

# 1. get Q1 and Q3 
Q = quantile(outlier_df$var1.1, probs = c(.25,.75), na.rm = FALSE)

# 2. get IQR
iqr = IQR(outlier_df$var1.1)

# 3. get upper and lower ranges
up <-  Q[2]+1.5*iqr # Upper Range  
low <- Q[1]-1.5*iqr # Lower Range

# 4. remove outliers (outlier_df is the name of my data frame, var1.1 is the name of the column that I am removing outliers from)

no_outliers_p <- outlier_df %>%
  filter(var1.1 > low & var1.1 < up) %>%
  ggplot(aes(x = var1.1)) +
  geom_boxplot() + 
  theme_classic() +
  labs(title = "Without Outliers") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

# patchwork to show plots
outlier_p / no_outliers_p
```
